{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mighty-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "differential-voluntary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Simoncen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "future-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/spyder-py3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "great-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Simoncen/spyder-py3/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(path)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "choice-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw = pd.read_csv(\"tweets_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attended-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Content</th>\n",
       "      <th>Location</th>\n",
       "      <th>Username</th>\n",
       "      <th>Retweet-Count</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Created at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://t.co/HnJUu3Oh30! Tuesday (3/30/2021) \\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snapshotnewsofc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-30 23:48:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@nderssonD @caitoz REGISTER TO VOTE PRAGMATIC ...</td>\n",
       "      <td>Earth Between Mexico &amp; Canada</td>\n",
       "      <td>tim39941098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-30 23:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@PatriciaIVicens REGISTER TO VOTE PRAGMATIC \\n...</td>\n",
       "      <td>Earth Between Mexico &amp; Canada</td>\n",
       "      <td>tim39941098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-30 23:43:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>@OneFreeBobcat REGISTER TO VOTE PRAGMATIC \\n#U...</td>\n",
       "      <td>Earth Between Mexico &amp; Canada</td>\n",
       "      <td>tim39941098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-30 23:39:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>REGISTER TO VOTE PRAGMATIC \\n#UBI /END POVERTY...</td>\n",
       "      <td>Earth Between Mexico &amp; Canada</td>\n",
       "      <td>tim39941098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-30 23:37:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "3           3             3   \n",
       "4           4             4   \n",
       "\n",
       "                                             Content  \\\n",
       "0  https://t.co/HnJUu3Oh30! Tuesday (3/30/2021) \\...   \n",
       "1  @nderssonD @caitoz REGISTER TO VOTE PRAGMATIC ...   \n",
       "2  @PatriciaIVicens REGISTER TO VOTE PRAGMATIC \\n...   \n",
       "3  @OneFreeBobcat REGISTER TO VOTE PRAGMATIC \\n#U...   \n",
       "4  REGISTER TO VOTE PRAGMATIC \\n#UBI /END POVERTY...   \n",
       "\n",
       "                         Location         Username  Retweet-Count  Favorites  \\\n",
       "0                             NaN  snapshotnewsofc              0          0   \n",
       "1  Earth Between Mexico & Canada       tim39941098              0          0   \n",
       "2  Earth Between Mexico & Canada       tim39941098              0          0   \n",
       "3  Earth Between Mexico & Canada       tim39941098              0          0   \n",
       "4  Earth Between Mexico & Canada       tim39941098              0          0   \n",
       "\n",
       "            Created at  \n",
       "0  2021-03-30 23:48:26  \n",
       "1  2021-03-30 23:45:58  \n",
       "2  2021-03-30 23:43:23  \n",
       "3  2021-03-30 23:39:56  \n",
       "4  2021-03-30 23:37:28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tweets_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "olympic-pension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  Unnamed: 0.1  Retweet-Count    Favorites\n",
      "count  4520.000000   4520.000000    4520.000000  4520.000000\n",
      "mean   2259.500000    746.225664       1.228982     2.739602\n",
      "std    1304.955938    434.884522      14.058724    34.295433\n",
      "min       0.000000      0.000000       0.000000     0.000000\n",
      "25%    1129.750000    369.750000       0.000000     0.000000\n",
      "50%    2259.500000    746.000000       0.000000     0.000000\n",
      "75%    3389.250000   1123.000000       1.000000     1.000000\n",
      "max    4519.000000   1499.000000     868.000000  2130.000000\n"
     ]
    }
   ],
   "source": [
    "print(tweets_raw.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legislative-leone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4520 entries, 0 to 4519\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     4520 non-null   int64 \n",
      " 1   Unnamed: 0.1   4520 non-null   int64 \n",
      " 2   Content        4520 non-null   object\n",
      " 3   Location       3424 non-null   object\n",
      " 4   Username       4520 non-null   object\n",
      " 5   Retweet-Count  4520 non-null   int64 \n",
      " 6   Favorites      4520 non-null   int64 \n",
      " 7   Created at     4520 non-null   object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 282.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tweets_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optical-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4471 entries, 0 to 4519\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Content        4471 non-null   object        \n",
      " 1   Location       3386 non-null   object        \n",
      " 2   Username       4471 non-null   object        \n",
      " 3   Retweet-Count  4471 non-null   int64         \n",
      " 4   Favorites      4471 non-null   int64         \n",
      " 5   Created at     4471 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 244.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We do not need first two columns. Let's drop them out.\n",
    "tweets_raw.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\"], axis=1, inplace=True)\n",
    "# Drop duplicated rows\n",
    "tweets_raw.drop_duplicates(inplace=True)\n",
    "# Created at column's type should be datatime\n",
    "tweets_raw[\"Created at\"] = pd.to_datetime(tweets_raw[\"Created at\"])\n",
    "# Print the info again\n",
    "print(tweets_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "classical-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "surrounded-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Simoncen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "functioning-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Simoncen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "infectious-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Simoncen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fundamental-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word_tokenize and stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sunrise-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process_tweets(tweet):\n",
    "    \n",
    "    # Remove links\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove mentions and hashtag\n",
    "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "    \n",
    "    # Tokenize the words\n",
    "    tokenized = word_tokenize(tweet)\n",
    "\n",
    "    # Remove the stop words\n",
    "    tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenized = [lemmatizer.lemmatize(token, pos='a') for token in tokenized]\n",
    "\n",
    "    # Remove non-alphabetic characters and keep the words contains three or more letters\n",
    "    tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chief-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function and store the result into a new column\n",
    "tweets_raw[\"Processed\"] = tweets_raw[\"Content\"].str.lower().apply(process_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "timely-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tuesday, headlines, today, snapshotnews, fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[cutting, voting, times, limiting, number, bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[register, vote, pragmatic, ubi, poverty, unem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Processed\n",
       "0   [tuesday, headlines, today, snapshotnews, fact...\n",
       "1   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "2   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "3   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "4   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "5   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "6   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "7   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "8   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "9   [register, vote, pragmatic, ubi, poverty, unem...\n",
       "10  [cutting, voting, times, limiting, number, bal...\n",
       "11  [register, vote, pragmatic, ubi, poverty, unem...\n",
       "12  [register, vote, pragmatic, ubi, poverty, unem...\n",
       "13  [register, vote, pragmatic, ubi, poverty, unem...\n",
       "14  [register, vote, pragmatic, ubi, poverty, unem...\n",
       "15  [register, vote, pragmatic, ubi, poverty, unem..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the first fifteen rows of Processed\n",
    "display(tweets_raw[[\"Processed\"]].head(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "industrial-speed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>263</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>285</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>278</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Words\n",
       "0        303     28\n",
       "1        312     36\n",
       "2        288     33\n",
       "3        292     34\n",
       "4        341     36\n",
       "...      ...    ...\n",
       "4515     263     41\n",
       "4516     200     24\n",
       "4517      66      8\n",
       "4518     285     26\n",
       "4519     278     43\n",
       "\n",
       "[4471 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the tweet lengths\n",
    "tweets_raw[\"Length\"] = tweets_raw[\"Content\"].str.len()\n",
    "# Get the number of words in tweets\n",
    "tweets_raw[\"Words\"] = tweets_raw[\"Content\"].str.split().str.len()\n",
    "# Display the new columns\n",
    "display(tweets_raw[[\"Length\", \"Words\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "seventh-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing values with unknown tag\n",
    "tweets_raw[\"Location\"].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fitting-ecuador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: ['unknown' 'Earth Between Mexico & Canada ' '@datop, earth sky moon' ...\n",
      " 'Local to Worldwide...' 'Born & Raise in (Da)Bronx ' 'Atlanta']\n",
      "Unique Value count: 1331\n"
     ]
    }
   ],
   "source": [
    "# Print the unique locations and number of unique locations\n",
    "print(\"Unique Values:\",tweets_raw[\"Location\"].unique())\n",
    "print(\"Unique Value count:\",len(tweets_raw[\"Location\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incorporated-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycountryNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n",
      "Building wheels for collected packages: pycountry\n",
      "  Building wheel for pycountry (setup.py): started\n",
      "  Building wheel for pycountry (setup.py): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746863 sha256=b2303b5852a1c46227ddd05f8142549305e5bce2094243e1460b6b2a5acf18c7\n",
      "  Stored in directory: c:\\users\\simoncen\\appdata\\local\\pip\\cache\\wheels\\09\\eb\\0d\\4ee773c6a4aadc2a43cb5c1d07f268f13c4cdc0eec88e7c1ef\n",
      "Successfully built pycountry\n",
      "Installing collected packages: pycountry\n",
      "Successfully installed pycountry-20.7.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "multiple-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pycountry\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "environmental-value",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown' 'IL' 'US' 'CA' 'IN' 'HK' 'MY' 'JP' 'AU' 'QA' 'DE' 'AL' 'ES'\n",
      " 'LK' 'NG' 'GB' 'FR' 'SO' 'IE' 'JE' 'SG' 'TR' 'BW' 'KE' 'JM' 'DO' 'GE'\n",
      " 'NZ' 'CH' 'NI' 'MT']\n",
      "Number of unique values: 31\n"
     ]
    }
   ],
   "source": [
    "def get_countries(location):\n",
    "    \n",
    "    # If location is a country name return its alpha2 code\n",
    "    if pycountry.countries.get(name= location):\n",
    "        return pycountry.countries.get(name = location).alpha_2\n",
    "    \n",
    "    # If location is a subdivisions name return the countries alpha2 code\n",
    "    try:\n",
    "        pycountry.subdivisions.lookup(location)\n",
    "        return pycountry.subdivisions.lookup(location).country_code\n",
    "    except:\n",
    "        # If the location is neither country nor subdivision return the \"unknown\" tag\n",
    "        return \"unknown\"\n",
    "\n",
    "# Call the function and store the country codes in the Country column\n",
    "tweets_raw[\"Country\"] = tweets_raw[\"Location\"].apply(get_countries)\n",
    "\n",
    "# Print the unique values\n",
    "print(tweets_raw[\"Country\"].unique())\n",
    "\n",
    "# Print the number of unique values\n",
    "print(\"Number of unique values:\",len(tweets_raw[\"Country\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "laden-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "serious-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw[\"Processed\"] = [\" \".join(Processed) for Processed in tweets_raw[\"Processed\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "demographic-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4471x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 55181 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abhi</th>\n",
       "      <th>abia</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ableg</th>\n",
       "      <th>abortionismurder</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>ישראל</th>\n",
       "      <th>더로즈</th>\n",
       "      <th>엔하이픈</th>\n",
       "      <th>𝘽𝙅𝙋</th>\n",
       "      <th>𝘽𝙆𝙐</th>\n",
       "      <th>𝘿𝙞𝙨𝙩𝙧𝙞𝙘𝙩</th>\n",
       "      <th>𝙆𝙖𝙣𝙘𝙝𝙚𝙚𝙥𝙪𝙧𝙖𝙢</th>\n",
       "      <th>𝙈𝙇𝘼</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abandoned  abc  abdication  abhi  abia  ability  able  ableg  \\\n",
       "0      0.0        0.0  0.0         0.0   0.0   0.0      0.0   0.0    0.0   \n",
       "1      0.0        0.0  0.0         0.0   0.0   0.0      0.0   0.0    0.0   \n",
       "2      0.0        0.0  0.0         0.0   0.0   0.0      0.0   0.0    0.0   \n",
       "3      0.0        0.0  0.0         0.0   0.0   0.0      0.0   0.0    0.0   \n",
       "4      0.0        0.0  0.0         0.0   0.0   0.0      0.0   0.0    0.0   \n",
       "\n",
       "   abortionismurder  ...  zoom  zuckerberg  ישראל  더로즈  엔하이픈  𝘽𝙅𝙋  𝘽𝙆𝙐  \\\n",
       "0               0.0  ...   0.0         0.0    0.0  0.0   0.0  0.0  0.0   \n",
       "1               0.0  ...   0.0         0.0    0.0  0.0   0.0  0.0  0.0   \n",
       "2               0.0  ...   0.0         0.0    0.0  0.0   0.0  0.0  0.0   \n",
       "3               0.0  ...   0.0         0.0    0.0  0.0   0.0  0.0  0.0   \n",
       "4               0.0  ...   0.0         0.0    0.0  0.0   0.0  0.0  0.0   \n",
       "\n",
       "   𝘿𝙞𝙨𝙩𝙧𝙞𝙘𝙩  𝙆𝙖𝙣𝙘𝙝𝙚𝙚𝙥𝙪𝙧𝙖𝙢  𝙈𝙇𝘼  \n",
       "0       0.0           0.0  0.0  \n",
       "1       0.0           0.0  0.0  \n",
       "2       0.0           0.0  0.0  \n",
       "3       0.0           0.0  0.0  \n",
       "4       0.0           0.0  0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create our contextual stop words\n",
    "tfidf_stops = [\"online\",\"class\",\"course\",\"learning\",\"learn\",\n",
    "\"teach\",\"teaching\",\"distance\",\"distancelearning\",\"education\",\n",
    "\"teacher\",\"student\",\"grade\",\"classes\",\"computer\",\"onlineeducation\", \"onlinelearning\", \"school\", \"students\",\"class\",\"virtual\",\"eschool\", \"virtuallearning\", \"educated\", \"educates\", \"teaches\", \"studies\", \"study\", \"semester\", \"elearning\",\"teachers\", \"lecturer\", \"lecture\", \"amp\",\"academic\", \"admission\", \"academician\", \"account\", \"action\" \n",
    "\"add\", \"app\", \"announcement\", \"application\", \"adult\", \"classroom\", \"system\", \"video\", \"essay\", \"homework\",\"work\",\"assignment\",\"paper\", \"get\", \"math\", \"project\", \"science\", \"physics\", \"lesson\",\"courses\", \"assignments\", \"know\", \"instruction\",\"email\", \"discussion\",\"home\", \"college\",\"exam\"\"use\",\"fall\",\"term\",\"proposal\",\"one\",\"review\",\n",
    "\"proposal\", \"calculus\", \"search\", \"research\", \"algebra\"]\n",
    "# Initialize a Tf-idf Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words= tfidf_stops)\n",
    "# Fit and transform the vectorizer\n",
    "tfidf_matrix = vectorizer.fit_transform(tweets_raw[\"Processed\"])\n",
    "# Let's see what we have\n",
    "display(tfidf_matrix)\n",
    "# Create a DataFrame for tf-idf vectors and display the first rows\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns= vectorizer.get_feature_names())\n",
    "display(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "modern-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data as a csv file\n",
    "tweets_raw.to_csv(\"tweets_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
